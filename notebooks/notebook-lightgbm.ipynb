{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6af38676",
      "metadata": {
        "id": "6af38676"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pyarrow.parquet as pq\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# from ydata_profiling import ProfileReport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c68c4070",
      "metadata": {
        "id": "c68c4070"
      },
      "outputs": [],
      "source": [
        "TRAIN_FILE = \"data/train.parquet\"\n",
        "TARGET_CHANNELS_FILE = \"data/target_channels.csv\"\n",
        "TEST_FILE = \"data/test.parquet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2bf05fe9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "2bf05fe9",
        "outputId": "e249e578-a8d3-4ff5-c466-6635a583e24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (14728321, 8)\n",
            "Test shape: (521280, 7)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>is_anomaly</th>\n",
              "      <th>channel_41</th>\n",
              "      <th>channel_42</th>\n",
              "      <th>channel_43</th>\n",
              "      <th>channel_44</th>\n",
              "      <th>channel_45</th>\n",
              "      <th>channel_46</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.812578</td>\n",
              "      <td>0.786344</td>\n",
              "      <td>0.771900</td>\n",
              "      <td>0.799178</td>\n",
              "      <td>0.816855</td>\n",
              "      <td>0.765296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.812578</td>\n",
              "      <td>0.786344</td>\n",
              "      <td>0.771900</td>\n",
              "      <td>0.799178</td>\n",
              "      <td>0.816855</td>\n",
              "      <td>0.765296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.821213</td>\n",
              "      <td>0.789557</td>\n",
              "      <td>0.770317</td>\n",
              "      <td>0.809411</td>\n",
              "      <td>0.816006</td>\n",
              "      <td>0.765296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.819642</td>\n",
              "      <td>0.786344</td>\n",
              "      <td>0.770317</td>\n",
              "      <td>0.807050</td>\n",
              "      <td>0.816855</td>\n",
              "      <td>0.766985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.821996</td>\n",
              "      <td>0.788753</td>\n",
              "      <td>0.770317</td>\n",
              "      <td>0.807837</td>\n",
              "      <td>0.818551</td>\n",
              "      <td>0.761073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  is_anomaly  channel_41  channel_42  channel_43  channel_44  channel_45  \\\n",
              "0   0           0    0.812578    0.786344    0.771900    0.799178    0.816855   \n",
              "1   1           0    0.812578    0.786344    0.771900    0.799178    0.816855   \n",
              "2   2           0    0.821213    0.789557    0.770317    0.809411    0.816006   \n",
              "3   3           0    0.819642    0.786344    0.770317    0.807050    0.816855   \n",
              "4   4           0    0.821996    0.788753    0.770317    0.807837    0.818551   \n",
              "\n",
              "   channel_46  \n",
              "0    0.765296  \n",
              "1    0.765296  \n",
              "2    0.765296  \n",
              "3    0.766985  \n",
              "4    0.761073  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "starter_ch = [f\"channel_{i}\" for i in range(41, 47)]\n",
        "\n",
        "df_train = pd.read_parquet(\n",
        "    TRAIN_FILE,\n",
        "    columns=[\"id\", \"is_anomaly\"] + starter_ch\n",
        ")\n",
        "\n",
        "df_test = pd.read_parquet(\n",
        "    TEST_FILE,\n",
        "    columns=[\"id\"] + starter_ch\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Test shape:\", df_test.shape)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ecbddeeb",
      "metadata": {
        "id": "ecbddeeb"
      },
      "outputs": [],
      "source": [
        "# profile = ProfileReport(df_train, title=\"Profiling Report\")\n",
        "# profile.to_file(\"report.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2394b5e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2394b5e5",
        "outputId": "9ad74e77-6974-4fac-8b73-846e8526f951"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id              int64\n",
            "is_anomaly      uint8\n",
            "channel_41    float32\n",
            "channel_42    float32\n",
            "channel_43    float32\n",
            "channel_44    float32\n",
            "channel_45    float32\n",
            "channel_46    float32\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df_train.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51917b6",
      "metadata": {
        "id": "f51917b6"
      },
      "source": [
        "¿Por qué este método?\n",
        "\n",
        "    Identificación clara de missing: marcamos explícitamente los 0.0 como NaN, distinguiéndolos de ceros reales (aunque aquí 0 no es físico).\n",
        "\n",
        "    Sencillez y eficiencia: LOCF/FOCB es muy rápido en series largas y no inventa valores nuevos, simplemente replica un valor cercano.\n",
        "\n",
        "    Preserva la dinámica local: al copiar el último valor conocido, no introduces saltos extraños ni picos artificiales que desentonen en tu ventana de análisis.\n",
        "\n",
        "    Adecuado para huecos pequeños y dispersos: en tu serie los ceros aparecen en bloques cortos. Este método arrastra un valor ligeramente desfasado solo durante ese breve intervalo, minimizando el sesgo.\n",
        "\n",
        "Si luego quisieras suavizar aún más, podrías incorporar interpolación lineal o un filtro de Kalman, pero para arrancar rápido y sin romper la continuidad, LOCF+FOCB es la opción más práctica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0c0466a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c0466a4",
        "outputId": "f4ec38ed-1172-45a9-96de-abea07969de8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Canales a imputar: ['channel_41', 'channel_42', 'channel_43', 'channel_44', 'channel_45', 'channel_46']\n",
            "NaNs tras imputación: 0\n"
          ]
        }
      ],
      "source": [
        "# 1. Detectar canales con ceros sentinela\n",
        "zero_counts = (df_train[starter_ch] == 0.0).sum()\n",
        "zero_chs = zero_counts[zero_counts > 0].index.tolist()\n",
        "print(\"Canales a imputar:\", zero_chs)\n",
        "\n",
        "# 2. Reemplazar 0.0 → NaN\n",
        "df_train[zero_chs] = df_train[zero_chs].replace(0.0, np.nan)\n",
        "\n",
        "# 3. Imputar con forward-fill y backward-fill\n",
        "df_train[zero_chs] = df_train[zero_chs].ffill().bfill()\n",
        "\n",
        "# 4. Verificar que ya no quedan NaN\n",
        "print(\"NaNs tras imputación:\", df_train[zero_chs].isna().sum().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ded1ea93",
      "metadata": {
        "id": "ded1ea93"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "df_train[starter_ch] = scaler.fit_transform(df_train[starter_ch])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e48c302f",
      "metadata": {
        "id": "e48c302f"
      },
      "outputs": [],
      "source": [
        "# División temporal manual (80 % primeros para train, 20 % últimos para validation)\n",
        "split = int(len(df_train) * 0.8)\n",
        "\n",
        "train_df = df_train.iloc[:split].reset_index(drop=True)\n",
        "val_df   = df_train.iloc[split:].reset_index(drop=True)\n",
        "\n",
        "X_train = train_df[starter_ch]\n",
        "y_train = train_df[\"is_anomaly\"]\n",
        "X_val   = val_df[starter_ch]\n",
        "y_val   = val_df[\"is_anomaly\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b01ca421",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b01ca421",
        "outputId": "2ee11bf5-25ba-49fc-d270-c53dc0a3dd5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train features shape: (11782656, 30)\n",
            "Val   features shape: (2945665, 30)\n"
          ]
        }
      ],
      "source": [
        "# Parámetro de ventana\n",
        "W = 100\n",
        "\n",
        "# 1️⃣ Crear rolling window sobre X_train\n",
        "roll_train = X_train.rolling(window=W, min_periods=1)\n",
        "X_train_feat = pd.DataFrame(index=X_train.index)\n",
        "\n",
        "for ch in starter_ch:\n",
        "    X_train_feat[f\"{ch}_mean_{W}\"] = roll_train[ch].mean()\n",
        "    X_train_feat[f\"{ch}_std_{W}\"]  = roll_train[ch].std().fillna(0)\n",
        "    X_train_feat[f\"{ch}_min_{W}\"]  = roll_train[ch].min()\n",
        "    X_train_feat[f\"{ch}_max_{W}\"]  = roll_train[ch].max()\n",
        "    X_train_feat[f\"{ch}_diff\"]     = X_train[ch].diff().fillna(0)\n",
        "\n",
        "# 2️⃣ Crear rolling window sobre X_val\n",
        "roll_val = X_val.rolling(window=W, min_periods=1)\n",
        "X_val_feat = pd.DataFrame(index=X_val.index)\n",
        "\n",
        "for ch in starter_ch:\n",
        "    X_val_feat[f\"{ch}_mean_{W}\"] = roll_val[ch].mean()\n",
        "    X_val_feat[f\"{ch}_std_{W}\"]  = roll_val[ch].std().fillna(0)\n",
        "    X_val_feat[f\"{ch}_min_{W}\"]  = roll_val[ch].min()\n",
        "    X_val_feat[f\"{ch}_max_{W}\"]  = roll_val[ch].max()\n",
        "    X_val_feat[f\"{ch}_diff\"]     = X_val[ch].diff().fillna(0)\n",
        "\n",
        "# 3️⃣ Verificar shapes\n",
        "print(\"Train features shape:\", X_train_feat.shape)\n",
        "print(\"Val   features shape:\", X_val_feat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6b741c6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b741c6d",
        "outputId": "a9cae86e-a6e5-4b8b-9969-47333258becd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train feat scaled shape: (11782656, 30)\n",
            "Val   feat scaled shape: (2945665, 30)\n"
          ]
        }
      ],
      "source": [
        "# 4️⃣ Escalado de las features de ventana\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler_feat = StandardScaler()\n",
        "X_train_feat_scaled = scaler_feat.fit_transform(X_train_feat)\n",
        "X_val_feat_scaled   = scaler_feat.transform(X_val_feat)\n",
        "\n",
        "# Verificar\n",
        "print(\"Train feat scaled shape:\", X_train_feat_scaled.shape)\n",
        "print(\"Val   feat scaled shape:\", X_val_feat_scaled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee0757b1",
      "metadata": {
        "id": "ee0757b1"
      },
      "source": [
        "## Entrenamiento de modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7906d49",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# %pip install lightgbm -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5pvrzIiJxae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5pvrzIiJxae",
        "outputId": "8216b738-e277-484b-e2dc-08856ae2d539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 1233929, number of negative: 10548727\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.153215 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6362\n",
            "[LightGBM] [Info] Number of data points in the train set: 11782656, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.104724 -> initscore=-2.145802\n",
            "[LightGBM] [Info] Start training from score -2.145802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mgonz\\anaconda3\\envs\\recsys\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score en validación: 0.10371229202509057\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Crear y entrenar modelo\n",
        "lgb_model = lgb.LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgb_model.fit(X_train_feat_scaled, y_train)\n",
        "\n",
        "# Evaluar en validación\n",
        "y_val_pred = lgb_model.predict(X_val_feat_scaled)\n",
        "print(\"F1-score en validación:\", f1_score(y_val, y_val_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "oYFF11jWJxXd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYFF11jWJxXd",
        "outputId": "21de5550-1077-4a24-8242-097f22b18fbe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mgonz\\anaconda3\\envs\\recsys\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Archivo 'submission.csv' generado con éxito.\n"
          ]
        }
      ],
      "source": [
        "# Cargar test\n",
        "df_test = pd.read_parquet(TEST_FILE, columns=[\"id\"] + starter_ch)\n",
        "\n",
        "# Imputar ceros\n",
        "df_test[zero_chs] = df_test[zero_chs].replace(0.0, np.nan)\n",
        "df_test[zero_chs] = df_test[zero_chs].ffill().bfill()\n",
        "\n",
        "# Escalar señales\n",
        "df_test[starter_ch] = scaler.transform(df_test[starter_ch])\n",
        "\n",
        "# Crear features rolling\n",
        "roll_test = df_test[starter_ch].rolling(window=W, min_periods=1)\n",
        "X_test_feat = pd.DataFrame(index=df_test.index)\n",
        "\n",
        "for ch in starter_ch:\n",
        "    X_test_feat[f\"{ch}_mean_{W}\"] = roll_test[ch].mean()\n",
        "    X_test_feat[f\"{ch}_std_{W}\"]  = roll_test[ch].std().fillna(0)\n",
        "    X_test_feat[f\"{ch}_min_{W}\"]  = roll_test[ch].min()\n",
        "    X_test_feat[f\"{ch}_max_{W}\"]  = roll_test[ch].max()\n",
        "    X_test_feat[f\"{ch}_diff\"]     = df_test[ch].diff().fillna(0)\n",
        "\n",
        "# Escalar las nuevas features\n",
        "X_test_feat_scaled = scaler_feat.transform(X_test_feat)\n",
        "\n",
        "# Predicción\n",
        "y_pred_test = lgb_model.predict(X_test_feat_scaled)\n",
        "\n",
        "# Guardar submission\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": df_test[\"id\"],\n",
        "    \"is_anomaly\": y_pred_test.astype(int)\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✅ Archivo 'submission.csv' generado con éxito.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "recsys",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
